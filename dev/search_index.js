var documenterSearchIndex = {"docs":
[{"location":"examples/gp/","page":"Gaussian Process (GP)","title":"Gaussian Process (GP)","text":"EditURL = \"../../../examples/gp.jl\"","category":"page"},{"location":"examples/gp/","page":"Gaussian Process (GP)","title":"Gaussian Process (GP)","text":"This section shows simulated curves from Gaussian process with various kernels.","category":"page"},{"location":"examples/gp/","page":"Gaussian Process (GP)","title":"Gaussian Process (GP)","text":"using Random\nusing Plots\nusing LaTeXStrings\nusing MonotoneDecomposition: sigmoid, gp\nfunction plot_functions()\n    n = 100\n    Random.seed!(1)\n    x = sort(rand(n)) * 2 .- 1\n    figsize = (400, 400)\n    fig1 = plot(x, x .^ 3, label = L\"x^3\", ls = :solid, size = figsize, legend = :top)\n    plot!(fig1, x, x .^ 2, label = L\"x^2\", ls = :dash)\n    plot!(fig1, x, exp.(x) .- 1, label = L\"\\exp(x)-1\", ls = :dot)\n    plot!(fig1, x, sigmoid.(x), label = L\"1/(1+\\exp(-5x))\", ls = :dashdot)\n    plot!(fig1, x, sin.(2π * x), label = L\"\\sin(2\\pi x)\", ls = :dashdotdot)\n    # plot(x, gp(x, kernel = \"SE_0.1\"))\n    fig2 = plot(x, gp(x, kernel = \"SE_1\"), label = \"SE_1\", ls = :solid, size = figsize, legend = :topright)\n    plot!(fig2, x, gp(x, kernel = \"SE_0.1\"), label = \"SE_0.1\", ls = :dash)\n    plot!(fig2, x, gp(x, kernel = \"SE_0.5\"), label = \"SE_0.5\", ls = :dot)\n    fig3 = plot(x, gp(x, kernel = \"Mat12_1\"), label = \"Mat12\", ls = :solid, size = figsize, legend = :topleft)\n    plot!(fig3, x, gp(x, kernel = \"Mat32_1\"), label = \"Mat32\", ls = :dash)\n    plot!(fig3, x, gp(x, kernel = \"Mat52_1\"), label = \"Mat52\", ls = :dot)\n    plot!(fig3, x, gp(x, kernel = \"RQ_1_0.5\"), label = \"RQ\", ls = :dashdot)\n    plot!(fig3, x, gp(x, kernel = \"Periodic_1_1\"), ls = :dashdotdot, label = \"Periodic\")\n    return plot(fig1, fig2, fig3, layout = (1, 3), size = (3*figsize[1], figsize[2]) )\n#    savefig(\"~/PGitHub/overleaf/MonoDecomp/figs/funcs.pdf\") # saved for paper\nend","category":"page"},{"location":"examples/gp/","page":"Gaussian Process (GP)","title":"Gaussian Process (GP)","text":"plot functions generated from Gaussian Process","category":"page"},{"location":"examples/gp/","page":"Gaussian Process (GP)","title":"Gaussian Process (GP)","text":"plot_functions()","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"EditURL = \"../../../examples/md_SE.jl\"","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"This section shows how to perform monotone decomposition on a noised random curve generated from Gaussian process.","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"using MonotoneDecomposition\nusing Plots\nusing Random","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Firstly, generate random data from Gaussian process with square kernel,","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"seed = 16\nRandom.seed!(seed)\nx, y, x0, y0 = gen_data(100, 0.5, \"SE_1\");\nnothing #hide","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Save the simulated data for reproducing if seed failed.","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"serialize(\"../res/demo/demo-seed$seed-se1_sigma0.5.sil\", [x, y, x0, y0])","category":"page"},{"location":"examples/md_SE/#With-Cubic-B-splines","page":"On A GP Random Function","title":"With Cubic B-splines","text":"","category":"section"},{"location":"examples/md_SE/#fixJ-true","page":"On A GP Random Function","title":"fixJ = true","text":"","category":"section"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Pefrom Monotone Decomposition with Cubic B-splines, where the number of basis functions is chosen by cross-validation for cubic splines.","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Random.seed!(seed)\nμs = 10.0 .^ (-6:0.05:0)\nD, μmin, errs, σerrs = cv_mono_decomp_cs(x, y, ss = μs,\n                            fixJ = true, x0 = x0,\n                            figname = \"cvspl.png\",\n                            nfold = 10, nfold_pre = 10);\nyhat, yhatnew = cubic_spline(D.workspace.J)(x, y, x0);\nnothing #hide","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"The CV error curve for J is","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"(Image: )","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"And the CV error curve for μ is","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"(Image: )","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Plot the fitted curves:","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"plot([x, y], [x0, y0], D, yhatnew, prefix_title = \"SE (ℓ = 1.0, σ = 0.5): \", competitor = \"cs\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Save the figure:","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"savefig(\"../res/demo/demo-seed$seed-cs_vs_md-1J_and_mu-fit.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"tip: High-quality Figures\nHere for simplicty, we just used the default GR backend of Plots.jl. But for a high-quality figure as in our paper, we will use the PGFPlotsX backend.","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"tip: Re-plot CV Curve for Cubic Spline\nIf figname is provided, the CV error curve for the cubic fitting step is stored in figname[1:end-4] * \"_bspl.png\" with the results figname[1:end-4] * \"_bspl_J.sil\". Thus, if necessary, we can re-plot it and save as a high-quality figure. Also save the CV results:mv(\"cvspl_bspl_J.sil\", \"../res/demo/cvspl_bspl_J.sil\", force = true)\nμerr, σerr, Js, nfold, ind = deserialize(\"../res/demo/cvspl_bspl_J.sil\")\ncvplot(μerr, nothing, 1.0 .* Js, nfold = nfold, ind0 = ind, lbl = L\"J\", title = \"10-fold CV Error (Cubic Spline)\")\nsavefig(\"../res/demo/demo-seed$seed-cs_vs_md-cs-cv.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Cross-validation plot","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"cvplot(errs, nothing, 1.0 * D.workspace.J:D.workspace.J, μs, lbl = [\"\", \"\\\\log_{10}\\\\mu\"], title = \"10-fold CV Error (J = $(D.workspace.J))\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Also backup the results","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"cp cvspl_Jmu.sil ../res/demo/","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"And save the figure","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"savefig(\"../res/demo/demo-seed$seed-cs_vs_md-1J_and_mu-cv.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"tip: Standard Error of CV error\nIf you want to add the error bar of the CV error, you can specify σerrs.cvplot(errs, σerrs, 1.0 * D.workspace.J:D.workspace.J, μs, lbl = [\"\", L\"\\log_{10}\\mu\"])","category":"page"},{"location":"examples/md_SE/#fixJ-false","page":"On A GP Random Function","title":"fixJ = false","text":"","category":"section"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Js = 4:50\nRandom.seed!(seed)\nD, μmin, errs, σerrs = cv_mono_decomp_cs(x, y, ss = μs, fixJ = false,\n                                        x0 = x0, Js = Js,\n                                        figname = \"cvbspl_varyJ.png\",\n                                        one_se_rule = false);\nplot([x, y], [x0, y0], D, yhatnew, prefix_title = \"SE (ℓ = 1, σ = 0.5): \", competitor = \"cs\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"savefig(\"../res/demo/demo-seed$seed-cs_vs_md-J_and_mu-fit.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"the CV error curve for the cubic spline","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"![][cvbsplvaryJbspl.png]","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"and the CV error curve for the decomposition with cubic splines","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"(Image: )","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Or we can replot the heatmap of CV-error along the two parameter (J, μ) is as follows,","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"cvplot(errs, nothing, Js * 1.0, μs, lbl = [\"J\", \"\\\\mu\"], title = \"10-fold CV Error\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"save figure","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"savefig(\"../res/demo/demo-seed$seed-cs_vs_md-J_and_mu-cv.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Backup the results","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"cp cvbspl_varyJ_bspl_J.sil ../res/demo\ncp cvbspl_varyJ_Jmu.sil ../res/demo","category":"page"},{"location":"examples/md_SE/#With-Smoothing-Splines","page":"On A GP Random Function","title":"With Smoothing Splines","text":"","category":"section"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Perform monotone decomposition with smoothing splines, where the tuning parameter λ and μ are tuned by 10-fold cross-validation,","category":"page"},{"location":"examples/md_SE/#Fix-λ","page":"On A GP Random Function","title":"Fix λ","text":"","category":"section"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Random.seed!(seed)\nD, μmin, μs, errs, σerrs, yhat, yhatnew = cv_mono_decomp_ss(x, y,\n                                            one_se_rule = false, x0 = x0,\n                                            figname = \"cvss_1lam.png\");\nnothing #hide","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Firstly, the cross-validation curve for the smoothing spline is","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"(Image: )","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"tip: Reproducing high-quality figure in manuscript\nTo produce a high-quality figure as in the manuscriptμerr, σerr, λs, nfold, ind = deserialize(\"cvss_1lam_ss.sil\")\n# cvplot(μerr, σerr, λs, nfold = nfold, ind0 = ind, lbl = \"\\\\lambda\")\ncvplot(μerr, nothing, λs, nfold = nfold, ind0 = ind, lbl = \"\\\\lambda\", title = \"10-fold CV (Smoothing Spline)\")\nsavefig(\"../res/demo/demo-seed$seed-ss_vs_md-ss-cv.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Then, given the optimal λ, tune μ, the CV error curve is as follows:","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"(Image: )","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"tip: Reproducing high-quality figure in manuscript\nTo produce a high-quality figure as in the manuscriptcvplot(errs, nothing, μs, lbl = \"\\\\mu\", title = \"10-fold CV Error (λ = $(D.λ))\")\nsavefig(\"../res/demo/demo-seed$seed-ss_vs_md-1lam_and_mu-cv.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Plot the decomposition,","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"plot([x, y], [x0, y0], D, yhatnew, prefix_title = \"SE (ℓ = 1, σ = 0.5): \")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"save the fitness curve","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"savefig(\"../res/demo/demo-seed$seed-ss_vs_md-1lam_and_mu-fit.pdf\")","category":"page"},{"location":"examples/md_SE/#Vary-λ","page":"On A GP Random Function","title":"Vary λ","text":"","category":"section"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Random.seed!(seed)\nD, μmin, μs, errs, σerrs, yhat, yhatnew = cv_mono_decomp_ss(x, y, one_se_rule = false, x0 = x0,\n                                            figname = \"cvss_varylam.png\",\n                                            method = \"double_grid\",\n                                            nλ = 50, ngrid_μ = 50,\n                                            μrange = [1e-7, 1.0],\n                                            rλs = 10.0 .^ (-1:0.05:1.2));\n\nplot([x, y], [x0, y0], D, yhatnew, prefix_title = \"SE (ℓ = 1, σ = 0.5): \")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"save the figure","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"savefig(\"../res/demo/demo-seed$seed-ss_vs_md-lam_and_mu-fit.pdf\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"The CV error heatmap is","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"(Image: )","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"Alternatively, we can replot it:","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"cvplot(\"/tmp/cvss_varylam.sil\", \"ss\")","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"save the results","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"mv cvss_varylam.sil ../res/demo/","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"and figure","category":"page"},{"location":"examples/md_SE/","page":"On A GP Random Function","title":"On A GP Random Function","text":"savefig(\"../res/demo/demo-seed$seed-ss_vs_md-lam_and_mu-cv.pdf\")","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [MonotoneDecomposition]\nOrder = [:type, :function]","category":"page"},{"location":"api/#MonotoneDecomposition._optim-Union{Tuple{T}, Tuple{AbstractVector{T}, MonotoneDecomposition.WorkSpaceCS, T}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition._optim","text":"_optim(y::AbstractVector, workspace::WorkSpaceCS, μs::AbstractVector)\n_optim(y::AbstractVector, J::Int, B::AbstractMatrix, H::AbstractMatrix{Int}, μs::AbstractVector)\n\nOptimization for monotone decomposition with cubic B-splines.\n\n_optim(y::AbstractVector, J::Int, B::AbstractMatrix, H::AbstractMatrix{Int}, L::AbstractMatrix, λs::AbstractVector, μs::AbstractVector)\n\nOptimization for monotone decomposition with smoothing splines.\n\n_optim!(y::AbstractVector, J::Int, B::AbstractMatrix, s::Union{Nothing, Real}, γhat::AbstractVector, H::AbstractMatrix{Int}; L, t, λ, μ)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.benchmarking","page":"API","title":"MonotoneDecomposition.benchmarking","text":"benchmarking(f::String; n = 100, \n                        σs = 0.2:0.2:1,\n                        competitor = \"ss_single_lambda\")\n\nRun benchmarking experiments for monotone decomposition on curve f. The candidates of f include:\n\nsimple functions: x^2, x^3, exp(x), sigmoid\nrandom functions generated from Gaussian Process: SE_1 SE_0.1 Mat12_1 Mat12_0.1 Mat32_1 Mat32_0.1 RQ_0.1_0.5 Periodic_0.1_4\n\nArguments\n\nn::Integer = 100: sample size for the simulated curve\nσs::AbstractVector: a vector of noise level to be investigated\ncompetitor::String: a string to indicate the strategy used in monotone decomposition. Possible choices:\nss_single_lambda: decomposition with smoothing splines ss with the single_lambda strategy\nss_fix_ratio: decomposition with smoothing splines ss with the fix_ratio strategy\nss_grid_search: decomposition with smoothing splines ss with the grid_search strategy\nss_iter_search: decomposition with smoothing splines ss with the iter_search strategy\nbspl: decomposition with cubic splines cs\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneDecomposition.benchmarking_cs","page":"API","title":"MonotoneDecomposition.benchmarking_cs","text":"benchmarking_cs(n, σ, f; figname_cv = nothing, figname_fit = nothing)\n\nRun benchmarking experiments for decomposition with cubic splines on n observations sampled from curve f with noise σ.\n\nOptional Arguments\n\nfigname_cv: if not nothing, the cross-validation error will be plotted and saved to the given path.\nfigname_fit: if not nothing, the fitted curves will be plotted and saved to the given path.\nJs: the candidates of number of basis functions.\nfixJ: whether to use the CV-tuned J from the crossponding cubic spline fitting.\nnfold: the number of folds in cross-validation procedure\none_se_rule: whether to use the one-standard-error rule to select the parameter after cross-validation procedure\nμs: the candidates of tuning parameters for the discrepancy parameter\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneDecomposition.benchmarking_ss","page":"API","title":"MonotoneDecomposition.benchmarking_ss","text":"benchmarking_ss(n::Int, σ::Float64, f::Union{Function, String}; \n                    method = \"single_lambda\")\n\nRun benchmarking experiments for decomposition with smoothing splines on n observations sampled from curve f with noise σ.\n\nArguments\n\nmethod::String = \"single_lambda\": strategy for decomposition with smoothing spline. Possible choices:\nsingle_lambda\nfix_ratio\ngrid_search\niter_search\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneDecomposition.build_model!-Union{Tuple{T}, Tuple{MonotoneDecomposition.WorkSpaceCS, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.build_model!","text":"build_model!(workspace::WorkSpaceCS, x::AbstractVector{T})\n\nCalculate components that construct the optimization problem for Monotone Decomposition with Cubic splines.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.conf_band_width-Tuple{AbstractMatrix}","page":"API","title":"MonotoneDecomposition.conf_band_width","text":"conf_band_width(CIs::AbstractMatrix)\n\nCalculate width of confidence bands.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.coverage_prob-Tuple{AbstractMatrix, AbstractVector}","page":"API","title":"MonotoneDecomposition.coverage_prob","text":"coverage_prob(CIs::AbstractMatrix, y0::AbstractVector)\n\nCalculate coverage probability given n x 2 CI matrix CIs and true vector y0 of size n.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cv_cubic_spline-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cv_cubic_spline","text":"cv_cubic_spline(x::AbstractVector, y::AbstractVector, xnew::AbstractVector)\n\nB-spline fitting with nfold CV-tuned J from Js.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cv_mono_decomp_cs-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cv_mono_decomp_cs","text":"cv_mono_decomp_cs(x::AbstractVector, y::AbstractVector, xnew::AbstractVector; )\ncv_mono_decomp_cs(x::AbstractVector, y::AbstractVector; fixJ = true)\n\nCross-validation for Monotone Decomposition with Cubic B-splines. Parameters J and s (μ if s_is_μ) are tuned by cross-validation.\n\nif fixJ == true, then J is CV-tuned by the corresponding cubic B-spline fitting\nif fixJ == false, then both J and s would be tuned by cross-validation.\n\nArguments\n\nfigname: if not nothing, then the CV erro figure will be saved to the given name (can include the path)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cv_mono_decomp_cs-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cv_mono_decomp_cs","text":"cv_mono_decomp_cs(x::AbstractVector, y::AbstractVector)\n\nCross-validation for monotone decomposition with cubic B-splines when the fixed J is CV-tuned by the corresponding cubic B-spline fitting method.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cv_mono_decomp_ss-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cv_mono_decomp_ss","text":"cv_mono_decomp_ss(x::AbstractVector, y::AbstractVector)\n\nCross Validation for Monotone Decomposition with Smoothing Splines. With λ tuned by smoothing spline, and then perform golden search for μ.\n\nReturns\n\nD: a MonoDecomp object.\nworkspace: workspace contained some intermediate results\nμmin: the parameter μ that achieve the smallest CV error\nμs: the investigated parameter μ\n\nExample\n\nx, y, x0, y0 = gen_data(100, 0.001, \"SE_0.1\")\nres, workspace = cv_mono_decomp_ss(x, y, one_se_rule = true, figname = \"/tmp/p.png\", tol=1e-3)\nyup = workspace.B * res.γup\nydown = workspace.B * res.γdown\nscatter(x, y)\nscatter!(x, yup)\nscatter!(x, ydown)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cv_one_se_rule-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cv_one_se_rule","text":"cv_one_se_rule(μs::AbstractVector{T}, σs::AbstractVector{T}; small_is_simple = true)\ncv_one_se_rule(μs::AbstractMatrix{T}, σs::AbstractMatrix{T}; small_is_simple = [true, true])\ncv_one_se_rule2(μs::AbstractMatrix{T}, σs::AbstractMatrix{T}; small_is_simple = [true, true])\n\nReturn the index of parameter(s) (1dim or 2-dim) that minimize the CV error with one standard error rule.\n\nFor 2-dim parameters, cv_one_se_rule2 adopts a grid search for μ+σ while cv_one_se_rule searchs after fixing one optimal parameter.  The potential drawback of cv_one_se_rule2 is that we might fail to determine the simplest model when both parameters are away from the optimal parameters. So we recommend cv_one_se_rule.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cvfit-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, Real, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cvfit","text":"Given `μmax`, and construct μs = (1:nμ) ./ nμ * μmax. If the optimal `μ` near the boundary, double or halve `μmax`.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cvfit_gss-Union{Tuple{T}, NTuple{4, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cvfit_gss","text":"cvfit_gss(x, y, μrange, λs)\n\nFor each λ in λs, perform cvfit(x, y, μrange, λ), and store the current best CV error. Finally, return the smallest one.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cvfit_gss-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}, Real}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.cvfit_gss","text":"cvfit_gss(x, y, μrange, λ; λ_is_μ)\n\nCross-validation by Golden Section Searching μinμrangegivenλ`.\n\nIf λ_is_μ, search λ in μrange given λ (μ)\nNote that one_se_rule is not suitable for the golden section search.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.cvplot","page":"API","title":"MonotoneDecomposition.cvplot","text":"cvplot(sil::String)\ncvplot(μerr::AbstractVector, σerr::Union{Nothing, AbstractVector{T}}, paras::AbstractVector)\ncvplot(μerr::AbstractMatrix, σerr::AbstractMatrix, para1::AbstractVector, para2::AbstractVector)\n\nPlot the cross-validation curves.\n\n\n\n\n\n","category":"function"},{"location":"api/#MonotoneDecomposition.demo_data-Tuple{}","page":"API","title":"MonotoneDecomposition.demo_data","text":"demo_data()\n\nGenerate demo data for illustration. (Figure 6 in the paper)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.div_into_folds-Tuple{Int64}","page":"API","title":"MonotoneDecomposition.div_into_folds","text":"div_into_folds(N::Int; K = 10, seed = 1234)\n\nEqually divide 1:N into K folds with random seed seed. Specially,\n\nIf seed is negative, it is a non-random division, where the i-th fold would be the i-th equidistant range.\nIf seed = 0, it is a non-random division, where each fold consists of equidistant indexes.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.gen_data-Tuple{Int64, Union{Nothing, Real}, Union{Function, String}}","page":"API","title":"MonotoneDecomposition.gen_data","text":"gen_data(n::Int, σ::Union{Real, Nothing}, f::Union{Function, String}; xmin = -1, xmax = 1, k = 10)\n\nGenerate n data points (xi, yi) from curve f with noise level σ, i.e., yi = f(xi) + N(0, σ^2).\n\nArguments\n\nfor f\nif f is a Function, just take y = f(x)\nif f = \"MLP\", it will be a simple neural network with one layer.\notherwise, it accepts the string with format KernelName_Para[_OtherPara] representing some Gaussian Processes, including\nSE, Mat12, Mat32, Mat52, Para: the length scale parameter ℓ\nPoly: Para is the degree parameter p\nRQ: Para is ℓ and OtherPara is α\nfor σ: the noise level\nif σ is nothing, then σ is calculated to achieve given signal-to-noise ratio (snr)\nif seed is not nothing, it ensures the same random function from Gaussian process, but it does not influence the random noises.\n\nReturns\n\nIt returns four vectors, x, y, x0, y0, where\n\nx, y: pair points of length n.\nx0, y0: true curve without noise, represented by k*n points.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.gen_data_bowman-Tuple{}","page":"API","title":"MonotoneDecomposition.gen_data_bowman","text":"gen_data_bowman()\n\nGenerate Curves for Monotonicity Test used in Bowman et al. (1998)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.gen_data_ghosal-Tuple{}","page":"API","title":"MonotoneDecomposition.gen_data_ghosal","text":"gen_data_ghosal()\n\nGenerate curves used in Ghosal et al. (2000).\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.gen_mono_data-Tuple{}","page":"API","title":"MonotoneDecomposition.gen_mono_data","text":"gen_mono_data()\n\nGenerate monotonic curves, used for checking type I error under H0. (Table 4 and Figure 5 in the paper)\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.gp-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.gp","text":"gp(x; K)\n\nGenerate a random Gaussian vector with mean zero and covariance matrix Σij = K(xi, xj).\n\nThe candidates of kernel K include SE, Mat12, Mat32, Mat52.\n\nSee also: https://stats.hohoweiya.xyz/2021/12/13/GP/\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.mono_decomp-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.mono_decomp","text":"mono_decomp(y::AbstractVector)\n\nPerform monotone decomposition on vector y, and return yup, ydown.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.mono_decomp_cs-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.mono_decomp_cs","text":"mono_decomp_cs(x::AbstractVector, y::AbstractVector)\n\nMonotone Decomposition with Cubic B-splines by solving an optimization problem.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.mono_decomp_ss-Union{Tuple{T}, Tuple{MonotoneDecomposition.WorkSpaceSS, AbstractVector{T}, AbstractVector{T}, AbstractFloat, AbstractFloat}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.mono_decomp_ss","text":"mono_decomp_ss(workspace::WorkSpaceSS, x::AbstractVector{T}, y::AbstractVector{T}, λ::AbstractFloat, μ::AbstractFloat)\n\nMonotone decomposition with smoothing splines.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.mono_test_bootstrap_ss-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T<:Real","page":"API","title":"MonotoneDecomposition.mono_test_bootstrap_ss","text":"mono_test_bootstrap_ss(x, y)\n\nPerform monotonicity test after monotone decomposition with smoothing splines.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.recover-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.recover","text":"recover(Σ)\n\nRecover matrix from the vector-stored Σ.\n\n\n\n\n\n","category":"method"},{"location":"api/#MonotoneDecomposition.smooth_spline-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, AbstractVector{T}}} where T<:AbstractFloat","page":"API","title":"MonotoneDecomposition.smooth_spline","text":"smooth_spline(x::AbstractVector, y::AbstractVector, xnew::AbstractVector)\n\nPerform smoothing spline on (x, y), and make predictions on xnew.\n\nReturns: yhat, ynewhat,....\n\n\n\n\n\n","category":"method"},{"location":"api/#RecipesBase.plot-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}, MonotoneDecomposition.MonoDecomp, AbstractVector}} where T<:(AbstractVector)","page":"API","title":"RecipesBase.plot","text":"plot(obs, truth, D::MonoDecomp, other)\n\nPlot the noised observations, the true curve, and the fitting from monotone decomposition D and other fitting technique.\n\nobs: usually be [x, y]\ntruth: usually be [x0, y0]\nD: a MonoDecomp object\nother: the fitted curve [x0, other] by other method, where x0 is omitted.\n\nA typical usage can be plot([x, y], [x0, y0], D, yhatnew, prefix_title = \"SE (ℓ = 1, σ = 0.5): \")\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict-Tuple{MonotoneDecomposition.MonoDecomp, AbstractVector}","page":"API","title":"StatsAPI.predict","text":"predict(D::MonoDecomp, xnew)\n\nPredict at xnew given decomposition D.\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict-Tuple{MonotoneDecomposition.WorkSpaceSS, AbstractVector, AbstractVecOrMat}","page":"API","title":"StatsAPI.predict","text":"predict(W::WorkSpaceSS, xnew::AbstractVector, γhat::AbstractVecOrMat)\npredict(W::WorkSpaceCS, xnew::AbstractVector, γhat::AbstractVecOrMat)\n\nMake multiple predictions at xnew for each column of γhat.\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict-Tuple{MonotoneDecomposition.WorkSpaceSS, AbstractVector, AbstractVector, AbstractVector}","page":"API","title":"StatsAPI.predict","text":"predict(W::WorkSpaceSS, xnew::AbstractVector, γup::AbstractVector, γdown::AbstractVector)\npredict(W::WorkSpaceCS, xnew::AbstractVector, γup::AbstractVector, γdown::AbstractVector)\n\nPredict yup and ydown at xnew given workspace W and decomposition coefficients γup and γdown.\n\n\n\n\n\n","category":"method"},{"location":"examples/sample_size/","page":"Effects of Sample Size","title":"Effects of Sample Size","text":"EditURL = \"../../../examples/sample_size.jl\"","category":"page"},{"location":"examples/sample_size/","page":"Effects of Sample Size","title":"Effects of Sample Size","text":"This section aims to investigate the effect of sample size.","category":"page"},{"location":"examples/sample_size/","page":"Effects of Sample Size","title":"Effects of Sample Size","text":"using MonotoneDecomposition\nusing Plots\nusing LinearAlgebra\nusing Random","category":"page"},{"location":"examples/sample_size/#With-Cubic-B-splines-(fitJ)","page":"Effects of Sample Size","title":"With Cubic B-splines (fitJ)","text":"","category":"section"},{"location":"examples/sample_size/","page":"Effects of Sample Size","title":"Effects of Sample Size","text":"seed = 16\nns = [20, 50, 100, 200, 500]\n\nErr1 = Float64[]\nErr2 = Float64[]\nμs = 10.0 .^ (-6:0.05:0)\nfor n in ns\n    Random.seed!(16)\n    x, y, x0, y0 = gen_data(n, 0.5, \"SE_1\");\n    D, μmin, errs, σerrs = cv_mono_decomp_cs(x, y, ss = μs,\n                            fixJ = true, x0 = x0,\n                            figname = \"cvspl_n$n.png\",\n                            nfold = 10, nfold_pre = 10);\n    yhat, yhatnew = cubic_spline(D.workspace.J)(x, y, x0);\n    yup, ydown = predict(D.workspace, x0, D.γup, D.γdown)\n    e1 = norm(yup + ydown - y0)^2 / length(y0)\n    e2 = norm(yhatnew - y0)^2 / length(y0)\n    append!(Err1, e1)\n    append!(Err2, e2)\nend","category":"page"},{"location":"examples/sample_size/","page":"Effects of Sample Size","title":"Effects of Sample Size","text":"Plot the results","category":"page"},{"location":"examples/sample_size/","page":"Effects of Sample Size","title":"Effects of Sample Size","text":"plot(ns, Err1, label = \"MDCS\", markershape = :circle, xlab = \"sample size n\", ylab = \"Err\")\nplot!(ns, Err2, label = \"CS\", markershape = :rect)","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"EditURL = \"../../../examples/solution_path.jl\"","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"using MonotoneDecomposition\nusing Plots\nusing Random\n\nRandom.seed!(123)\nx, y, x0, y0 = gen_data(100, 0.1, x -> exp(x));\nμs = 10.0 .^ (-2:0.2:3)\nnμ = length(μs)\nres = Array{Any, 1}(undef, nμ)","category":"page"},{"location":"examples/solution_path/#J-8","page":"Solution Path","title":"J = 8","text":"","category":"section"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"for i in 1:nμ\n    res[i] = mono_decomp_cs(x, y, J = 8, s = μs[i], s_is_μ=true)\nend\nγups = hcat([res[i].γup for i in 1:nμ]...)\nγdowns = hcat([res[i].γdown for i in 1:nμ]...)","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"save the results","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"serialize(\"../res/solution_path/expx-sigma0.1-J8.sil\", [γups, γdowns, res, μs, x, y])","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"calculate the coefficients via the least square solution","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"γls = inv(res[1].workspace.B' * res[1].workspace.B) * res[1].workspace.B' * y\nc = mean(res[1].workspace.B * γls) / 2\nγups_calculated = [γls ./ (μ + 1) .+ (μ - 1) / (μ + 1) * c for μ in μs]\nγups_ls = hcat(γups_calculated...)","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"plot the coefficients along the tuning parameter μ","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"default_colors = palette(:auto)\nplot(log10.(μs), γups[1, :], label = L\"\\hat\\gamma_1^u\", xlab = L\"\\log_{10}\\; \\mu\", color = default_colors[1])\nplot!(log10.(μs), γups_ls[1, :], label = L\"\\gamma_1^{u}\", ls = :dash, lw = 2, color = default_colors[1])\nplot!(log10.(μs), γups[2, :], label = L\"\\hat\\gamma_2^u\", color = default_colors[2])\nplot!(log10.(μs), γups_ls[2, :], label = L\"\\gamma_2^{u}\", ls = :dash, lw = 2, color = default_colors[2])\nplot!(log10.(μs), γups[3, :], label = L\"\\hat\\gamma_3^u\", color = default_colors[3])\nplot!(log10.(μs), γups_ls[3, :], label = L\"\\gamma_3^{u}\", ls = :dash, lw = 2, color = default_colors[3])\nplot!(log10.(μs), γups[4, :], label = L\"\\hat\\gamma_4^u\", color = default_colors[4])\nplot!(log10.(μs), γups_ls[4, :], label = L\"\\gamma_4^{u}\", ls = :dash, lw = 2, color = default_colors[4])\nplot!(log10.(μs), γups[5, :], label = L\"\\hat\\gamma_5^u\", color = default_colors[5])\nplot!(log10.(μs), γups_ls[5, :], label = L\"\\gamma_5^{u}\", ls = :dash, lw = 2, color = default_colors[5])\nplot!(log10.(μs), γups[6, :], label = L\"\\hat\\gamma_6^u\", color = default_colors[6])\nplot!(log10.(μs), γups_ls[6, :], label = L\"\\gamma_6^{u}\", ls = :dash, lw = 2, color = default_colors[6])\nplot!(log10.(μs), γups[7, :], label = L\"\\hat\\gamma_7^u\", color = default_colors[7])\nplot!(log10.(μs), γups_ls[7, :], label = L\"\\gamma_7^{u}\", ls = :dash, lw = 2, color = default_colors[7])\nplot!(log10.(μs), γups[8, :], label = L\"\\hat\\gamma_8^u\", color = default_colors[8])\nplot!(log10.(μs), γups_ls[8, :], label = L\"\\gamma_8^{u}\", ls = :dash, lw = 2, color = default_colors[8])","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"save the results","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"savefig(\"../res/solution_path/expx-sigma0.1-J8-up.pdf\")","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"plot the difference between the estimated coefficients and the theoretical constant vector","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"diff_downs = sum((γdowns .- c).^2, dims = 1)[:]\nplot(log10.(μs), log10.(diff_downs), xlab = L\"\\log_{10}\\; \\mu\", label = \"\", ylab = L\"\\log_{10}\\Vert \\hat\\gamma^d - \\gamma^d\\Vert_2^2\")","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"save the figure","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"savefig(\"../res/solution_path/expx-sigma0.1-J8-down.pdf\")","category":"page"},{"location":"examples/solution_path/#J-9","page":"Solution Path","title":"J = 9","text":"","category":"section"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"for i in 1:nμ\n    res[i] = mono_decomp_cs(x, y, J = 9, s = μs[i], s_is_μ=true)\nend\nγups = hcat([res[i].γup for i in 1:nμ]...)\nγdowns = hcat([res[i].γdown for i in 1:nμ]...)","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"save the results","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"serialize(\"../res/solution_path/expx-sigma0.1-J9.sil\", [γups, γdowns, res, μs, x, y])","category":"page"},{"location":"examples/solution_path/#without-tied-information","page":"Solution Path","title":"without tied information","text":"","category":"section"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"calculate the coefficients via the least square solution","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"γls = inv(res[1].workspace.B' * res[1].workspace.B) * res[1].workspace.B' * y\nc = mean(res[1].workspace.B * γls) / 2\nγups_calculated = [γls ./ (μ + 1) .+ (μ - 1) / (μ + 1) * c for μ in μs]\nγups_ls = hcat(γups_calculated...)","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"plot the coefficients along the tuning parameter μ","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"plot(log10.(μs), γups[1, :], label = L\"\\hat\\gamma_1^u\", xlab = L\"\\log_{10}\\; \\mu\", color = default_colors[1], lw = 3, alpha = 0.5)\nplot!(log10.(μs), γups_ls[1, :], label = L\"\\gamma_1^{u}\", ls = :dash, lw = 2, color = default_colors[1])\nplot!(log10.(μs), γups[2, :], label = L\"\\hat\\gamma_2^u\", color = default_colors[2])\nplot!(log10.(μs), γups_ls[2, :], label = L\"\\gamma_2^{u}\", ls = :dash, lw = 2, color = default_colors[2])\nplot!(log10.(μs), γups[3, :], label = L\"\\hat\\gamma_3^u\", color = default_colors[3])\nplot!(log10.(μs), γups_ls[3, :], label = L\"\\gamma_3^{u}\", ls = :dash, lw = 2, color = default_colors[3])\nplot!(log10.(μs), γups[4, :], label = L\"\\hat\\gamma_4^u\", color = default_colors[4])\nplot!(log10.(μs), γups_ls[4, :], label = L\"\\gamma_4^{u}\", ls = :dash, lw = 2, color = default_colors[4])\nplot!(log10.(μs), γups[5, :], label = L\"\\hat\\gamma_5^u\", color = default_colors[5])\nplot!(log10.(μs), γups_ls[5, :], label = L\"\\gamma_5^{u}\", ls = :dash, lw = 2, color = default_colors[5])\nplot!(log10.(μs), γups[6, :], label = L\"\\hat\\gamma_6^u\", color = default_colors[6])\nplot!(log10.(μs), γups_ls[6, :], label = L\"\\gamma_6^{u}\", ls = :dash, lw = 2, color = default_colors[6])\nplot!(log10.(μs), γups[7, :], label = L\"\\hat\\gamma_7^u\", color = default_colors[7])\nplot!(log10.(μs), γups_ls[7, :], label = L\"\\gamma_7^{u}\", ls = :dash, lw = 2, color = default_colors[7])\nplot!(log10.(μs), γups[8, :], label = L\"\\hat\\gamma_8^u\", color = default_colors[8])\nplot!(log10.(μs), γups_ls[8, :], label = L\"\\gamma_8^{u}\", ls = :dash, lw = 2, color = default_colors[8])\nplot!(log10.(μs), γups[9, :], label = L\"\\hat\\gamma_9^u\", color = default_colors[9])\nplot!(log10.(μs), γups_ls[9, :], label = L\"\\gamma_9^{u}\", ls = :dash, lw = 2, color = default_colors[9])","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"save the figure","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"savefig(\"../res/solution_path/expx-sigma0.1-J9-up-ls.pdf\")","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"diff_downs = sum((γdowns .- c).^2, dims = 1)[:]\nplot(log10.(μs), log10.(diff_downs), xlab = L\"\\log_{10}\\; \\mu\", label = \"\", ylab = L\"\\log_{10}\\Vert \\hat\\gamma^d - \\gamma^d\\Vert_2^2\")","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"save the figure","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"savefig(\"../res/solution_path/expx-sigma0.1-J9-down-ls.pdf\")","category":"page"},{"location":"examples/solution_path/#with-tied-information","page":"Solution Path","title":"with tied information","text":"","category":"section"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"G = hcat(zeros(8), 1.0I(8))\nG[1, 1] = 1\nγGls = G' * inv(G * res[1].workspace.B' * res[1].workspace.B * G') * G * res[1].workspace.B' * y\nc = mean(res[1].workspace.B * γGls) / 2\nγups_calculated = [γGls ./ (μ + 1) .+ (μ - 1) / (μ + 1) * c for μ in μs]\nγups_ls = hcat(γups_calculated...)","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"plot the results","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"plot(log10.(μs), γups[1, :], label = L\"\\hat\\gamma_1^u\", xlab = L\"\\log_{10}\\; \\mu\", color = default_colors[1], lw = 3, alpha = 0.5)\nplot!(log10.(μs), γups_ls[1, :], label = L\"\\gamma_1^{u}\", ls = :dash, lw = 2, color = default_colors[1])\nplot!(log10.(μs), γups[2, :], label = L\"\\hat\\gamma_2^u\", color = default_colors[2])\nplot!(log10.(μs), γups_ls[2, :], label = L\"\\gamma_2^{u}\", ls = :dash, lw = 2, color = default_colors[2])\nplot!(log10.(μs), γups[3, :], label = L\"\\hat\\gamma_3^u\", color = default_colors[3])\nplot!(log10.(μs), γups_ls[3, :], label = L\"\\gamma_3^{u}\", ls = :dash, lw = 2, color = default_colors[3])\nplot!(log10.(μs), γups[4, :], label = L\"\\hat\\gamma_4^u\", color = default_colors[4])\nplot!(log10.(μs), γups_ls[4, :], label = L\"\\gamma_4^{u}\", ls = :dash, lw = 2, color = default_colors[4])\nplot!(log10.(μs), γups[5, :], label = L\"\\hat\\gamma_5^u\", color = default_colors[5])\nplot!(log10.(μs), γups_ls[5, :], label = L\"\\gamma_5^{u}\", ls = :dash, lw = 2, color = default_colors[5])\nplot!(log10.(μs), γups[6, :], label = L\"\\hat\\gamma_6^u\", color = default_colors[6])\nplot!(log10.(μs), γups_ls[6, :], label = L\"\\gamma_6^{u}\", ls = :dash, lw = 2, color = default_colors[6])\nplot!(log10.(μs), γups[7, :], label = L\"\\hat\\gamma_7^u\", color = default_colors[7])\nplot!(log10.(μs), γups_ls[7, :], label = L\"\\gamma_7^{u}\", ls = :dash, lw = 2, color = default_colors[7])\nplot!(log10.(μs), γups[8, :], label = L\"\\hat\\gamma_8^u\", color = default_colors[8])\nplot!(log10.(μs), γups_ls[8, :], label = L\"\\gamma_8^{u}\", ls = :dash, lw = 2, color = default_colors[8])\nplot!(log10.(μs), γups[9, :], label = L\"\\hat\\gamma_9^u\", color = default_colors[9])\nplot!(log10.(μs), γups_ls[9, :], label = L\"\\gamma_9^{u}\", ls = :dash, lw = 2, color = default_colors[9])","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"save the figure","category":"page"},{"location":"examples/solution_path/","page":"Solution Path","title":"Solution Path","text":"savefig(\"../res/solution_path/expx-sigma0.1-J9-up-gls.pdf\")","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"EditURL = \"../../../examples/benchmark_parallel.jl\"","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"Benchmarking","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"using Distributed\n@everywhere using MonotoneDecomposition","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"Candidate functions","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"fs = [\"x^2\" \"x^3\" \"exp(x)\" \"sigmoid\" \"SE_1\" \"SE_0.1\" \"Mat12_1\" \"Mat12_0.1\" \"Mat32_1\" \"Mat32_0.1\" \"RQ_0.1_0.5\" \"Periodic_0.1_4\"]\n\nnrep = 1\nnλ = 2\nnfold = 2\nidxf = 1:2 # run locally\ncompetitor = \"ss_single_lambda\"\nnλ = ifelse(occursin(\"single_lambda\", competitor), 1, nλ)\none_se_rule = false\nresfolder0 = \"/tmp\"\ntimestamp = replace(strip(read(`date -Iseconds`, String)), \":\" => \"_\")\nif length(ARGS) > 0\n    @info \"Use args passed from CLI\"\n    competitor = ARGS[1]\n    resfolder0 = ARGS[2]\n    if !isdir(resfolder0)\n        mkdir(resfolder0)\n    end\n    nλ = parse(Int, ARGS[3])\n    nrep = parse(Int, ARGS[4])\n    nfold = parse(Int, ARGS[5])\n    one_se_rule = parse(Bool, ARGS[6])\n    idxf = 1:length(fs)\n    if length(ARGS) > 6\n        timestamp = AGRS[end] # passed from scripts\n    end\nend\nresfolder = joinpath(resfolder0, \"nrep$nrep-nfold$nfold-nlam$nλ-1se$(one_se_rule)-$competitor-$timestamp\")\nif !isdir(resfolder)\n    mkdir(resfolder)\nend\n@info \"Results are saved into $resfolder\"\n\npmap(\n    f->benchmarking(\n        f;\n        σs = [0.1, 0.2, 0.4, 0.5, 1.0, 1.5, 2.0], # noise level to be surveyed\n        jplot = false, # μerr vs σs\n        nrep = nrep, # NB: for fast auto-generation procedure, only use nrep = 1; in the paper, use nrep = 100\n        competitor = competitor,\n        nfold = nfold, # number of folds\n        one_se_rule = one_se_rule,\n        nλ = nλ, # the number of λ to be searched\n        rλ = 0.5, # the search region of λ, (1-rλ, 1+rλ)*λ\n        resfolder = resfolder,\n        verbose = false,\n        show_progress = f == \"x^3\" # keep one progressbar\n    ),\n    fs[idxf]\n);\nnothing #hide","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"tip: run from command line\njulia examples/benchmark.jl ss_single_lambda /tmp 2 1 2 falseYou can also enable the debug mode to print more internal steps as followsJULIA_DEBUG=MonotoneDecomposition julia examples/benchmark.jl ss_single_lambda /tmp 2 1 2 false","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"summary the results","category":"page"},{"location":"examples/benchmark_parallel/","page":"Benchmarking in Parallel","title":"Benchmarking in Parallel","text":"# MonotoneDecomposition.summary(resfolder = resfolder, format = \"tex\")","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"EditURL = \"../../../examples/benchmark.jl\"","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"Benchmarking","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"using MonotoneDecomposition","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"prefer Gurobi if possible","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"gurobi(1)","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"Candidate functions","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"fs = [\"x^2\" \"x^3\" \"exp(x)\" \"sigmoid\" \"SE_1\" \"SE_0.1\" \"Mat12_1\" \"Mat12_0.1\" \"Mat32_1\" \"Mat32_0.1\" \"RQ_0.1_0.5\" \"Periodic_0.1_4\"]\n\nnrep = 1\nnλ = 2\nnfold = 2\nf = fs[1]\ncompetitor = \"ss_single_lambda\"\nnλ = ifelse(occursin(\"single_lambda\", competitor), 1, nλ)\none_se_rule = false\nresfolder0 = \"/tmp\"\ntimestamp = replace(strip(read(`date -Iseconds`, String)), \":\" => \"_\")\nn = 100\nuse_snr = false\nif length(ARGS) > 0\n    @info \"Use args passed from CLI\"\n    competitor = ARGS[1]\n    resfolder0 = ARGS[2]\n    if !isdir(resfolder0)\n        mkdir(resfolder0)\n    end\n    nλ = parse(Int, ARGS[3])\n    nrep = parse(Int, ARGS[4])\n    nfold = parse(Int, ARGS[5])\n    one_se_rule = parse(Bool, ARGS[6])\n    f = ARGS[7]\n    if length(ARGS) > 7\n        timestamp = replace(strip(ARGS[8]), \":\" => \"_\") # passed from scripts\n        n = parse(Int, ARGS[9])\n        use_snr = parse(Bool, ARGS[10])\n    end\nend\nresfolder = joinpath(resfolder0, \"nrep$nrep-nfold$nfold-nlam$nλ-1se_$(one_se_rule)-$competitor-$timestamp-n$n-snr_$(use_snr)\")\nif !isdir(resfolder)\n    mkdir(resfolder)\nend\n@info \"Results are saved into $resfolder\"\n\nbenchmarking(\n    f;\n    n = n,\n    σs = [0.1, 0.2, 0.4, 0.5, 1.0, 1.5, 2.0], # noise level to be surveyed\n    snrs = [0.1, 0.5, 1, 2, 10], # SNR to be surveryed\n    use_snr = use_snr,\n    jplot = false, # μerr vs σs\n    nrep = nrep, # NB: for fast auto-generation procedure, only use nrep = 1; in the paper, use nrep = 100\n    competitor = competitor,\n    nfold = nfold, # number of folds\n    one_se_rule = one_se_rule,\n    nλ = nλ, # the number of λ to be searched\n    rλ = 0.5, # the search region of λ, (1-rλ, 1+rλ)*λ\n    resfolder = resfolder,\n    verbose = false,\n    show_progress = true,\n    multi_fix_ratio = true,\n    rλs = 10.0 .^ (-1:0.05:0.1)\n)","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"tip: run from command line\njulia examples/benchmark.jl ss_single_lambda /tmp 2 1 2 falseYou can also enable the debug mode to print more internal steps as followsJULIA_DEBUG=MonotoneDecomposition julia examples/benchmark.jl ss_single_lambda /tmp 2 1 2 false","category":"page"},{"location":"examples/benchmark/","page":"Benchmarking","title":"Benchmarking","text":"tip: summary results\nAfter obtaining results, we can obtain the summarized tex file (used in the manuscript) as follows.MonotoneDecomposition.summary(resfolder = resfolder)","category":"page"},{"location":"#MonotoneDecomposition.jl","page":"Home","title":"MonotoneDecomposition.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = MonotoneDecomposition","category":"page"},{"location":"","page":"Home","title":"Home","text":"MonotoneDecomposition.jl is a Julia package for monotone decomposition with monotone splines.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Check the following paper for more details.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Lijun Wang, Xiaodan Fan, Hongyu Zhao, and Jun S. Liu. “Decomposition with Monotone B-Splines: Fitting and Testing.” arXiv, January 12, 2024. http://arxiv.org/abs/2401.06383.","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"EditURL = \"../../../examples/anyJ.jl\"","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"This section aims to show for the cubic spline fitting with any number of basis functions J. If one applied the monotone decomposition, it can achieve a better performance.","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"using MonotoneDecomposition\nusing Plots\nusing Random","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"Firstly, generate random data from Gaussian process","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"seed = 16\nRandom.seed!(seed)\nx, y, x0, y0 = gen_data(100, 0.5, \"SE_1\");\nnothing #hide","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"the true curve and noisy observations are shown in the following figure","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"plot(x0, y0, label = \"truth\")\nscatter!(x, y, label = \"sample\")","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"compare the performance of cubic spline fitting (CS) and the corresponding fitting with monotone decomposition (MDCS)","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"Js = 4:50\nnJ = length(Js)\nerrs = zeros(nJ, 2)\nRandom.seed!(seed)\nfor i in 1:nJ\n    J = Js[i]\n    yhat_cs, y0hat_cs = cubic_spline(J)(x, y, x0)\n    errs[i, 1] = sum((y0 - y0hat_cs).^2) / length(y0)\n    D, _ = cv_mono_decomp_cs(x, y, Js = J:J, ss = 10.0 .^ (-6:0.05:0))\n    y0hat_md = predict(D, x0)\n    errs[i, 2] = sum((y0 - y0hat_md).^2) / length(y0)\nend","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"the CV optimized J should be","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"D, _ = cv_mono_decomp_cs(x, y, Js = Js, ss = 10.0 .^ (-6:0.05:0))\nD.workspace.J","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"save results","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"serialize(\"../res/demo/anyJ-seed$seed.sil\", [Js, errs, D.workspace.J])","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"plot the mean squared prediction error (MSPE) along the number of basis function J:","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"plot(Js, errs[:, 1], xlab = \"J\", ylab = \"MSPE\", label = \"CS\", markershape = :circle, legend = :topleft)\nplot!(Js, errs[:, 2], label = \"MDCS\", markershape = :star5)\nPlots.vline!([D.workspace.J], ls = :dash, label = \"CVCS\")","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"Locally, I will save the figure and present in the paper.","category":"page"},{"location":"examples/anyJ/","page":"CS vs MDCS under any J","title":"CS vs MDCS under any J","text":"savefig(\"../res/demo/anylam-seed$seed.pdf\")","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"EditURL = \"../../../examples/anylam.jl\"","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"This section aims to show for the smoothing spline fitting with arbitrary λ.","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"using MonotoneDecomposition\nusing Plots\nusing Random","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"Firstly, generate random data from Gaussian process","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"seed = 16\nRandom.seed!(seed)\nx, y, x0, y0 = gen_data(100, 0.5, \"SE_1\");\nnothing #hide","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"the true curve and noisy observations are shown in the following figure","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"plot(x0, y0, label = \"truth\")\nscatter!(x, y, label = \"sample\")","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"the CV-optimized λ for the smoothing spline","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"λs = 10.0 .^ (-8:1) # λs = 10.0 .^ (-8:0.1:1)\nyhat, _, λcv = MonotoneDecomposition.cv_smooth_spline(x, y, λs)\nnλ = length(λs)\nerrs = zeros(nλ, 2)\nμs = 10 .^ (-8:1) # μs = 10 .^ (-8:0.1:1)\nfor (i, λ) in enumerate(λs)\n    @info \"i = $i\"\n    # D, _ = MonotoneDecomposition.cvfit_gss(x, y, [1e-6, 1.0], λ, tol = 1e-2)\n    D, _ = MonotoneDecomposition.cvfit(x, y, μs, [λ])\n    y0hat_mdss = predict(D, x0)\n    y0hat_ss = MonotoneDecomposition.smooth_spline(x, y, x0, λ)\n    errs[i, :] .= [sum((y0hat_ss - y0).^2), sum((y0hat_mdss - y0).^2)] / length(y0)\nend","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"save results","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"serialize(\"../res/demo/anylam-seed$seed.sil\", [λs, errs, λcv])","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"idx = 1:nλ # idx = 2:2:nλ # if too many points (looks too busy)\nplot(log.(λs)[idx], errs[idx, 1], xlab = \"λ\", ylab = \"MSPE\", label = \"SS\", markershape = :circle, legend = :topright)\nplot!(log.(λs)[idx], errs[idx, 2], label = \"MDSS\", markershape = :star5)\nPlots.vline!([log.(λcv)], ls = :dash, label = \"CVSS\")","category":"page"},{"location":"examples/anylam/","page":"SS vs MDSS under any λ","title":"SS vs MDSS under any λ","text":"savefig(\"../res/demo/anylam-seed$seed.pdf\")","category":"page"}]
}
